trigger:
  - dev

pool:
  vmImage: 'ubuntu-latest'

variables:
  azure_subscription_id: "15e60859-88d7-4c84-943f-55488479910c"
  azure_client_id: "9a7b7fdd-5a88-46e3-8d9b-b78042012e30"
  azure_client_secret: "s6h8Q~WNY_QKu92SobDd7FnfSIWJsYSYmKeF2dw0"
  azure_tenant_id: "fd3a4a13-0cd8-4c1c-ba4c-e4995f5ee282"
  terraformVersion: '1.3.5'
  location: "East US"
  node_count: 2
  log_analytics_sku: "PerGB2018"

  resource_group_name: "Goreg4"
  storage_account_name: "goreg4"
  container_name: "goreg4container"
  aks_name: "goreg4-aks"
  log_analytics_workspace_name: "goreg4-analytics"
  diagnostic_setting_name: "goreg4-diagnostics"
  grafana_name: "Goreg4-Grafana"
  dcr_name: "PrometheusDCR"
  

stages:
- stage: Terraform
  displayName: 'Terraform Stage'
  jobs:
  - job: Terraform
    displayName: 'Terraform Deployment'
    steps:
    - script: |
        curl -LO https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh
        chmod +x install_linux.sh && ./install_linux.sh
        curl -sSL https://aka.ms/InstallAzureCLIDeb | sudo bash
        
        az login --service-principal -u $(azure_client_id) -p $(azure_client_secret) --tenant $(azure_tenant_id)
        az account set --subscription $(azure_subscription_id)
      displayName: 'Azure CLI Login'
    
    - script: |
        terraform init
      displayName: 'Terraform Init'

    - script: |
        check_resource_exists() {
          local resource_id="$1"
          if az resource show --ids "$resource_id" >/dev/null 2>&1; then
            echo "true"
          else
            echo "false"
          fi
        }

        RESOURCE_GROUP_ID="/subscriptions/$(azure_subscription_id)/resourceGroups/$(resource_group_name)"
        AKS_CLUSTER_ID="/subscriptions/$(azure_subscription_id)/resourceGroups/$(resource_group_name)/providers/Microsoft.ContainerService/managedClusters/$(aks_name)"
        STORAGE_ACCOUNT_ID="/subscriptions/$(azure_subscription_id)/resourceGroups/$(resource_group_name)/providers/Microsoft.Storage/storageAccounts/$(storage_account_name)"
        STORAGE_CONTAINER_ID="https://$(storage_account_name).blob.core.windows.net/$(container_name)"
        LOG_ANALYTICS_ID="/subscriptions/$(azure_subscription_id)/resourceGroups/$(resource_group_name)/providers/Microsoft.OperationalInsights/workspaces/$(log_analytics_workspace_name)"
        DIAGNOSTIC_SETTING_ID="/subscriptions/$(azure_subscription_id)/resourceGroups/$(resource_group_name)/providers/Microsoft.ContainerService/managedClusters/$(aks_name)|$(diagnostic_setting_name)"

        # Import or Create Resource Group
        if [[ "$(check_resource_exists $RESOURCE_GROUP_ID)" == "true" ]]; then
          terraform import azurerm_resource_group.example "$RESOURCE_GROUP_ID"
        else
          terraform apply -auto-approve -target=azurerm_resource_group.example
        fi

        # Import or Create AKS Cluster
        if [[ "$(check_resource_exists $AKS_CLUSTER_ID)" == "true" ]]; then
          terraform import azurerm_kubernetes_cluster.example "$AKS_CLUSTER_ID"
        else
          terraform apply -auto-approve -target=azurerm_kubernetes_cluster.example
        fi

        # Import or Create Storage Account
        if [[ "$(check_resource_exists $STORAGE_ACCOUNT_ID)" == "true" ]]; then
          terraform import azurerm_storage_account.example "$STORAGE_ACCOUNT_ID"
        else
          terraform apply -auto-approve -target=azurerm_storage_account.example
        fi

        # Import or Create Storage Container
        if [[ "$(check_resource_exists $STORAGE_CONTAINER_ID)" == "true" ]]; then
          terraform import azurerm_storage_container.example "$STORAGE_CONTAINER_ID"
        else
          terraform apply -auto-approve -target=azurerm_storage_container.example
        fi

        # Import or Create Log Analytics Workspace
        if [[ "$(check_resource_exists $LOG_ANALYTICS_ID)" == "true" ]]; then
          terraform import azurerm_log_analytics_workspace.example "$LOG_ANALYTICS_ID"
        else
          terraform apply -auto-approve -target=azurerm_log_analytics_workspace.example
        fi

        # Import or Create Diagnostic Setting
        EXISTING_DIAGNOSTIC_SETTING=$(az monitor diagnostic-settings list --resource $(AKS_CLUSTER_ID) --query "[?name=='$(diagnostic_setting_name)'].name" -o tsv)

        if [[ -z "$EXISTING_DIAGNOSTIC_SETTING" ]]; then
          # If the diagnostic setting does not exist, create it
          terraform apply -auto-approve -target=azurerm_monitor_diagnostic_setting.aks_metrics
        else
          echo "Diagnostic setting '$(diagnostic_setting_name)' already exists, skipping creation."
        fi
      displayName: 'Import or Create Resources Dynamically'

    - script: |
        terraform plan -out=tfplan
      displayName: 'Terraform Plan'
    
    - script: |
        terraform apply -auto-approve
      displayName: 'Terraform Apply'
      env:
        ARM_CLIENT_ID: $(azure_client_id)
        ARM_CLIENT_SECRET: $(azure_client_secret)
        ARM_TENANT_ID: $(azure_tenant_id)
        ARM_SUBSCRIPTION_ID: $(azure_subscription_id)

- stage: DeployMonitoringStandalone
  displayName: 'Deploy Prometheus and Grafana without dependencies'
  condition: always()
  jobs:
      - job: HelmDeployment
        displayName: 'Deploy Prometheus and Grafana via Helm'
        steps:
          - script: |
              # Log in to Azure
              az login --service-principal -u $(azure_client_id) -p $(azure_client_secret) --tenant $(azure_tenant_id)
              az account set --subscription $(azure_subscription_id)

              # Get AKS credentials
              az aks get-credentials --resource-group $(resource_group_name) --name $(aks_name)

              # Verify cluster connection
              kubectl cluster-info

              # Install Helm
              curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash

              # Add Helm repos
              helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
              helm repo add grafana https://grafana.github.io/helm-charts
              helm repo update

              # Install Prometheus and Grafana
              helm install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring --create-namespace --wait
              helm install grafana grafana/grafana --namespace monitoring --set adminPassword='yourpassword' --set service.type=LoadBalancer --wait

              # Verify deployments
              kubectl get pods -n monitoring
            displayName: 'Install Prometheus and Grafana via Helm'

- stage: EnablePrometheus
  displayName: 'Enable Managed Prometheus'
  condition: always()
  jobs:
      - job: EnablePrometheus
        steps:
          - script: |
              echo "🔑 Logging into Azure..."
              az login --service-principal -u $(azure_client_id) -p $(azure_client_secret) --tenant $(azure_tenant_id)
              az account set --subscription $(azure_subscription_id)

              echo "🔄 Enabling Managed Prometheus..."
              az aks update --resource-group $(resource_group_name) --name $(aks_name) --enable-azure-monitor-metrics
              echo "✅ Managed Prometheus enabled successfully!"
            displayName: 'Enable Managed Prometheus'


- stage: SetupGrafana
  displayName: 'Create Managed Grafana in Azure'
  condition: always()
  jobs:
      - job: CreateGrafana
        displayName: 'Ensure Managed Grafana Exists'
        steps:
          - script: |
              az login --service-principal -u $(azure_client_id) -p $(azure_client_secret) --tenant $(azure_tenant_id)
              az account set --subscription $(azure_subscription_id)

              # Check if Grafana exists
              if ! az grafana show --name $(grafana_name) --resource-group $(resource_group_name) &> /dev/null; then
                az grafana create --name $(grafana_name) --resource-group $(resource_group_name) --location "eastus"
              fi
            displayName: 'Create Grafana if not exists'

- stage: LinkGrafanaToPrometheus
  displayName: 'Link Grafana to Managed Prometheus'
  condition: always()
  jobs:
      - job: LinkGrafana
        displayName: 'Configure Grafana Data Source'
        steps:
          - script: |
              az login --service-principal -u $(azure_client_id) -p $(azure_client_secret) --tenant $(azure_tenant_id)
              az account set --subscription $(azure_subscription_id)

              # Get Prometheus URL
              PROMETHEUS_URL=$(az aks show --resource-group $(resource_group_name) --name $(aks_name) --query "addonProfiles.prometheus.config.prometheusEndpoint" -o tsv)

              # Ensure Prometheus is enabled
              if [ -z "$PROMETHEUS_URL" ]; then
                az aks enable-addons --resource-group $(resource_group_name) --name $(aks_name) --addons monitoring
                sleep 60  # Give some time for Prometheus to activate
                PROMETHEUS_URL=$(az aks show --resource-group $(resource_group_name) --name $(aks_name) --query "addonProfiles.prometheus.config.prometheusEndpoint" -o tsv)
              fi

              # Wait for Grafana to be ready
              sleep 30

              # Add Prometheus data source to Grafana
              az grafana data-source create --name $(grafana_name) --resource-group $(resource_group_name) --definition '{
                  "name": "Azure Monitor Prometheus",
                  "type": "prometheus",
                  "access": "proxy",
                  "url": "'"$PROMETHEUS_URL"'",
                  "isDefault": true
              }'

              # Verify data source was added
              az grafana data-source list --name $(grafana_name) --resource-group $(resource_group_name)
            displayName: 'Configure Grafana Data Source'

- stage: ConfigureDCR
  displayName: 'Configure Data Collection Rule'
  condition: always()
  jobs:
      - job: ConfigureDCR
        steps:
          - script: |
              echo "🔑 Logging into Azure..."
              az login --service-principal -u $(azure_client_id) -p $(azure_client_secret) --tenant $(azure_tenant_id)
              az account set --subscription $(azure_subscription_id)

              echo "🔄 Checking if Data Collection Rule (DCR) exists..."
              DCR_EXISTS=$(az monitor data-collection rule show --name $(dcr_name) --resource-group $(resource_group_name) --query "name" -o tsv || echo "not_found")

              if [ "$DCR_EXISTS" = "not_found" ]; then
                echo "🔄 Creating new Data Collection Rule (DCR) for Prometheus..."
                az monitor data-collection rule create \
                  --name $(dcr_name) \
                  --resource-group $(resource_group_name) \
                  --location $(location) \
                  --data-flows '[{"streams": ["Microsoft-PrometheusMetrics"], "destinations": ["azure-monitor-metrics"]}]' \
                  --destinations name=azure-monitor-metrics type=azure-monitor-metrics
                
                echo "✅ Data Collection Rule (DCR) created successfully!"
              else
                echo "✅ DCR already exists. Skipping creation."
              fi
            displayName: 'Create Data Collection Rule (DCR)'

- stage: EnableRecordingRules
  displayName: 'Enable Prometheus Recording Rules'
  condition: always()
  jobs:
      - job: EnableRecordingRules
        steps:
          - script: |
              echo "🔑 Logging into Azure..."
              az login --service-principal -u $(azure_client_id) -p $(azure_client_secret) --tenant $(azure_tenant_id)
              az account set --subscription $(azure_subscription_id)

              echo "🔄 Checking if Recording Rules are enabled..."
              RECORDING_RULES_ENABLED=$(az monitor metrics alert list --resource-group $(resource_group_name) --query "[?name=='PrometheusRecordingRules'].name" -o tsv || echo "not_found")

              if [ "$RECORDING_RULES_ENABLED" = "not_found" ]; then
                echo "🔄 Configuring Prometheus Recording Rules..."
                az monitor metrics alert create \
                  --name "PrometheusRecordingRules" \
                  --resource-group $(resource_group_name) \
                  --scopes "/subscriptions/$(azure_subscription_id)/resourceGroups/$(resource_group_name)/providers/Microsoft.Insights/dataCollectionRules/$(dcr_name)" \
                  --condition "avg AzureMonitorPrometheusRecordingRule > 0" \
                  --window-size 5m \
                  --evaluation-frequency 1m
                echo "✅ Prometheus Recording Rules enabled successfully!"
              else
                echo "✅ Recording Rules already configured. Skipping."
              fi
            displayName: 'Enable Prometheus Recording Rules'
            
- stage: FetchErrors
  displayName: 'Fetch All Errors from Logs'
  condition: always()
  jobs:
    - job: GetErrors
      displayName: 'Run KQL Queries to Fetch Errors'
      steps:
        - script: |
            echo "🔑 Logging into Azure..."
            az login --service-principal -u $(azure_client_id) -p $(azure_client_secret) --tenant $(azure_tenant_id)
            az account set --subscription $(azure_subscription_id)

            echo "🔎 Getting Workspace ID..."
            workspace_id=$(az monitor log-analytics workspace show \
              --resource-group $(resource_group_name) \
              --workspace-name $(log_analytics_workspace_name) \
              --query customerId -o tsv)

            if [ -z "$workspace_id" ]; then
              echo "❌ Failed to get Log Analytics Workspace ID"
              exit 1
            fi

            echo "🔎 Fetching all errors from Azure Monitor..."
            az monitor log-analytics query \
              --workspace "$workspace_id" \
              --analytics-query "
              AzureDiagnostics
              | where SeverityLevel == 'Error' or Level == 'Error'
              | project TimeGenerated, Resource, OperationName, Message, Category, _ResourceId
              | order by TimeGenerated desc" \
              --output table

            echo "🔎 Fetching all errors from Application Insights..."
            az monitor log-analytics query \
              --workspace "$workspace_id" \
              --analytics-query "
              union exceptions, traces
              | where severityLevel == 'Error'
              | project timestamp, message, type, operation_Name, cloud_RoleInstance
              | order by timestamp desc" \
              --output table

            echo "🔎 Fetching all errors from Kubernetes Logs..."
            az monitor log-analytics query \
              --workspace "$workspace_id" \
              --analytics-query "
              ContainerLog
              | where LogLevel == 'Error' or LogMessage contains 'error'
              | project TimeGenerated, Name, Namespace, LogMessage
              | order by TimeGenerated desc" \
              --output table
          displayName: 'Run KQL Queries for Errors'